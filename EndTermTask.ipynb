{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPaL+6yAf6euvTHLo066P1M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riasci/KomputasiIntelegensiaTasks/blob/main/EndTermTask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Ria Mulyadi\n",
        "\n",
        "NPM: 2206048556"
      ],
      "metadata": {
        "id": "zeiKvYD4cCuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "Model: CNN\n",
        "\n",
        "Referensi Model: https://dlvr.rantai.dev/docs/part-ii/chapter-5/"
      ],
      "metadata": {
        "id": "5Q_x_epOcMfd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn5ent6RlEPN",
        "outputId": "6fe5cb4b-4c30-482e-94b3-aa70bf850c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.11.10)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement python-zlib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for python-zlib\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install torch requests aiohttp python-zlib anyio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFtbtOxWllMl",
        "outputId": "2fb78fe7-e4ae-422f-b61c-a4f91854db58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Download Fashion MNIST dataset using kagglehub\n",
        "path = kagglehub.dataset_download(\"zalando-research/fashionmnist\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Define the path to the dataset\n",
        "data_path = os.path.join(path, \"fashionmnist\", \"versions\", \"4\")  # Adjusted path\n",
        "\n",
        "# Transformations for dataset (convert to tensor and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "train_dataset = FashionMNIST(data_path, train=True, download=True, transform=transform)\n",
        "test_dataset = FashionMNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the CNN model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.fc1 = nn.Linear(1024, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 28, 28)  # Reshape input to 1x28x28 images\n",
        "        x = nn.functional.relu(self.conv1(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = nn.functional.relu(self.conv2(x))\n",
        "        x = nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 1024)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and optimizer\n",
        "model = Net().cuda()  # Move model to GPU if available\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    for epoch in range(10):  # Training for 10 epochs\n",
        "        running_loss = 0.0\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            images, labels = images.cuda(), labels.cuda()  # Move data to GPU\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            outputs = model(images)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Calculate loss\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update the weights\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "# Testing function\n",
        "def test():\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader):\n",
        "            images, labels = images.cuda(), labels.cuda()  # Move data to GPU\n",
        "            outputs = model(images)  # Forward pass\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy: {100 * correct / total}%')\n",
        "\n",
        "# Run the training and testing\n",
        "train()\n",
        "test()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNuYDBcmlvkq",
        "outputId": "5311b1e3-a57d-45c1-99af-08ab719e44a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/zalando-research/fashionmnist/versions/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:16<00:00, 56.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4687754220879281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 59.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.30755398250909755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:16<00:00, 57.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.26317859985935155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:16<00:00, 56.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.2297681352016387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 60.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.20681978822119837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 60.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.1869982990192007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:16<00:00, 58.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.1711152231277052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 59.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.1549793298590555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 60.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.14002912203425855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [00:15<00:00, 59.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.1276080100717686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:02<00:00, 56.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}